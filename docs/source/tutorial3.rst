**************
Load Balancing
**************

Problem
=======

We often want to scale an application to run on more than one running container, either for performance or reliability reasons. In this tutorial, we'll add a load balancer to balance the load across two containers.

Setup
=====

In addition to our basic setup from the previous tutorials, you need to create a load balancer. In this example, we're using an AWS Elastic Load Balancer (ELB) and naming it *hello-world-elb*.

Configuration
=============

Here's the configuration file for this load balanced service::

    services:
      - name: hello-world-test
        cluster: hello-world-cluster
        count: 1
        family: hello-world
        load_balancer:
          service_role_arn: arn:aws:iam::123445564666:role/ecsServiceRole
          load_balancer_name: hello-world-elb
          container_name: hello-world
          container_port: 80
        containers:
          - name: hello-world
            image: tutum/hello-world
            cpu: 128
            memory: 256
            ports:
              - "80"
            command: /usr/bin/supervisord
            environment:
              - VAR1=test
              - VAR2=anothervar
              - DEBUG=True

Here we've added the new parameter, *load_balancer*. This corresponds to your AWS ELB.

Load Balancer Parameters
------------------------

ELB
^^^

The *load_balancer* parameter requires the following four parameters if you are using a classic AWS ELB:

*service_role_arn*
    The name or full ARN of the IAM role that allows ECS to make calls to your load balancer on your behalf. You will need to use the ARN that corresponds to your account.

*load_balancer_name*
    The name of the ELB.

*container_name*
    The name of the container to associate with the load balancer

*container_port*
    The port on the container to associate with the load balancer. This port must correspond to a container port on container container_name in your serviceâ€™s task definition

ALB or NLB
^^^^^^^^^^

AWS also offers the Application Load Balancers (ALB) and Network Load Balancers. If you are using one of those instead
of the ELB, you will still use the *load_balancer* parameter, but it will require *target_group_arn* to be specified,
rather than *load_balancer_name*:

*target_group_arn*
    The full ARN of the target group to use for this service.

Deploy
======

To deploy this service, run the same command we ran in the last tutorial::

    deploy create hello-world-test

To increase the number of running containers behind the load balancer to 2 instances, you can either modify the config, setting the count to::

    services:
      - name: hello-world-test
        cluster: hello-world-cluster
        count: 2
        family: hello-world
        load_balancer:
        ...

Then running *update*::

    deploy update hello-world-test

Or you can scale the container arbitrarily with the *scale* command::

    deploy scale test 2

